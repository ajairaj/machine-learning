{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import net_utils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load cifar-10 dataset\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "onehot_train = nu.convert_to_onehot(y_train, 10)\n",
    "onehot_test = nu.convert_to_onehot(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize some of the images\n",
    "fig, axes = plt.subplots(2,10,figsize=(20,5))\n",
    "ctr = 0;\n",
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        axes[i,j].imshow(np.squeeze(x_train[ctr]))\n",
    "        axes[i,j].axes.get_xaxis().set_visible(False)\n",
    "        axes[i,j].axes.get_yaxis().set_visible(False)\n",
    "        axes[i,j].set_title(str(y_train[ctr]))\n",
    "        ctr += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_cnn import basic_cnn as basic_cnn\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "class conv_net:\n",
    "    def __init__(self, im_size, n_chan, n_class, learning_rate):\n",
    "        self.im_size = im_size\n",
    "        self.n_chan = n_chan\n",
    "        self.n_class = n_class\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.inputs = tf.placeholder(tf.float32, (None, im_size, im_size, n_chan), name=\"inputs\")\n",
    "        self.targets = tf.placeholder(tf.float32, (None, n_class), name=\"targets\")\n",
    "\n",
    "        pred, cost = basic_cnn(self.inputs, self.targets)\n",
    "        self.pred = pred\n",
    "        self.cost = cost\n",
    "        \n",
    "        vars_to_minimize = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='conv_net')\n",
    "        self.opt = tf.train.AdamOptimizer(self.learning_rate).minimize(cost, var_list=vars_to_minimize)\n",
    "        \n",
    "    def parameter_count(self, full=False):\n",
    "        vars_to_minimize = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='conv_net')\n",
    "        nu.parameter_count(vars_to_minimize, full = False)\n",
    "        \n",
    "    def train_on_batch(self, inputs, targets, mb_sz = 32):\n",
    "        data_count = inputs.shape[0]\n",
    "\n",
    "        for i in range(0, data_count, mb_sz):\n",
    "            i_s = i\n",
    "            i_e = np.minimum(data_count, i + mb_sz)\n",
    "            sess_out = self.opt\n",
    "            feed_dict={self.inputs: inputs[i_s:i_e], self.targets: targets[i_s:i_e]}\n",
    "            sess.run(sess_out, feed_dict=feed_dict)\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "    def run_on_batch(self, inputs, targets, mb_sz = 32):\n",
    "        data_count = inputs.shape[0]\n",
    "        pred = np.zeros((data_count, self.n_class))\n",
    "        cost = 0\n",
    "\n",
    "        for i in range(0, data_count, mb_sz):\n",
    "            i_s = i\n",
    "            i_e = np.minimum(data_count, i + mb_sz)\n",
    "            \n",
    "            sess_out = [self.pred, self.cost]\n",
    "            feed_dict={self.inputs: inputs[i_s:i_e], self.targets: targets[i_s:i_e]}\n",
    "            results = sess.run(sess_out, feed_dict=feed_dict)\n",
    "            pred[i_s:i_e] = results[0]\n",
    "            cost += (results[1] / (i_e-i_s))\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        return pred, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters: 270270\n",
      "Epoch: 1/20... trn loss: 69.44757 tst loss: 14.46718\n",
      "Epoch: 2/20... trn loss: 60.96258 tst loss: 13.24848\n",
      "Epoch: 3/20... trn loss: 52.94173 tst loss: 12.20011\n",
      "Epoch: 4/20... trn loss: 48.66662 tst loss: 11.88518\n",
      "Epoch: 5/20... trn loss: 43.87060 tst loss: 11.60608\n",
      "Epoch: 6/20... trn loss: 42.03522 tst loss: 11.75096\n",
      "Epoch: 7/20... trn loss: 41.09631 tst loss: 12.10887\n"
     ]
    }
   ],
   "source": [
    "### clear the graph\n",
    "tf.reset_default_graph()\n",
    "### build the network\n",
    "net = conv_net(im_size = 32, n_chan = 3, n_class = 10, learning_rate = 1e-3)\n",
    "net.parameter_count()\n",
    "### initialze the session and variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) \n",
    "\n",
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    nu.shuffle_together(x_train, onehot_train)\n",
    "    net.train_on_batch(x_train, onehot_train)\n",
    "    _, trn_cost = net.run_on_batch(x_train, onehot_train)\n",
    "    _, tst_cost = net.run_on_batch(x_test, onehot_test)\n",
    "    \n",
    "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "          \"trn loss: {:.5f}\".format(trn_cost),\n",
    "          \"tst loss: {:.5f}\".format(tst_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
